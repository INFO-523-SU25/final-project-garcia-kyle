[
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Packet Traffic Learning",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats # for analysis plan"
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "Packet Traffic Learning",
    "section": "Dataset",
    "text": "Dataset\n\nnetwork_traffic_train = pd.read_csv('data/KDDTrain+.txt')\nnetwork_traffic_test = pd.read_csv('data/KDDTest+.txt')\n\ndf_train = network_traffic_train.copy()\ndf_test = network_traffic_test.copy()\n\n'''\nColumns recieved from kaggle project \nhttps://www.kaggle.com/code/faizankhandeshmukh/intrusion-detection-system\n\n'''\n\n# Define the list of column names based on the NSL-KDD dataset description\ncolumns = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n    'dst_host_srv_rerror_rate', 'attack', 'level'\n]\n\n# Assign the column names to the dataframe\ndf_train.columns = columns\ndf_test.columns = columns\n\n\nprint('Shapes (train, test):', df_train.shape, df_test.shape)\n\nShapes (train, test): (125972, 43) (22543, 43)\n\n\nWe are using a training and testing dataset of network intrusion detection from NSL-KDD from Kaggle. The intrusion detection network traffic training dataset contains 125,972 rows and 43 columns, and 22,543 rows and 43 columns in the test dataset.\nThe attack field indicates normal or anomalous (multi-class) observations which allows us to use learning approaches for classifying anomalous network activity. A new binary classification feature, is_anomalous, will be added to indicate if the network connection was anomalous or not. This will be the target field for the project.\nWe chose this dataset because it provides a rich and realistic representation of network traffic data. The presence of labeled data allows us to train and evaluate supervised models; the diversity and volume of traffic patterns make it well-suited for exploring unsupervised anomaly detection techniques as well. This balance between complexity and feature richness aligns well with our research questions and modeling goals."
  },
  {
    "objectID": "proposal.html#questions",
    "href": "proposal.html#questions",
    "title": "Packet Traffic Learning",
    "section": "Questions",
    "text": "Questions\nQ1. Using supervised machine learning models such as Long Short-Term Memory (LSTM) and Support Vector Machines (SVMs), can we accurately calssify network traffic as normal and anomalous based on labeled data? How do their performances compare in terms of accuracy, precision, recall, and F1-score?\nQ2. Can unsupervised learning methods such as K-Means Clustering and Density-Based Clustering (DBSCAN) detect anomalous patterns in network traffic without using labeled data?\nSummary. How do the supervised and unsupervised approaches compare?"
  },
  {
    "objectID": "proposal.html#dataset-analysis",
    "href": "proposal.html#dataset-analysis",
    "title": "Packet Traffic Learning",
    "section": "Dataset Analysis",
    "text": "Dataset Analysis\n\nVariables\n\n\n\n\n\n\n\n\nColumn Name\nData Type\nDescription\n\n\n\n\nduration\nint64\nLength (in seconds) of the connection.\n\n\nprotocol_type\nobject\nProtocol used (e.g., tcp, udp, icmp).\n\n\nservice\nobject\nNetwork service on the destination (e.g., http, telnet).\n\n\nflag\nobject\nStatus flag of the connection.\n\n\nsrc_bytes\nint64\nNumber of data bytes sent from source to destination.\n\n\ndst_bytes\nint64\nNumber of data bytes sent from destination to source.\n\n\nland\nint64\n1 if connection is from/to the same host/port; 0 otherwise.\n\n\nwrong_fragment\nint64\nNumber of wrong fragments.\n\n\nurgent\nint64\nNumber of urgent packets.\n\n\nhot\nint64\nNumber of “hot” indicators.\n\n\nnum_failed_logins\nint64\nNumber of failed login attempts.\n\n\nlogged_in\nint64\n1 if successfully logged in; 0 otherwise.\n\n\nnum_compromised\nint64\nNumber of compromised conditions.\n\n\nroot_shell\nint64\n1 if root shell is obtained; 0 otherwise.\n\n\nsu_attempted\nint64\n1 if “su root” command attempted; 0 otherwise.\n\n\nnum_root\nint64\nNumber of “root” accesses.\n\n\nnum_file_creations\nint64\nNumber of file creation operations.\n\n\nnum_shells\nint64\nNumber of shell prompts invoked.\n\n\nnum_access_files\nint64\nNumber of accesses to control files.\n\n\nnum_outbound_cmds\nint64\nNumber of outbound commands (always 0 in KDD99).\n\n\nis_host_login\nint64\n1 if login is to a host account; 0 otherwise.\n\n\nis_guest_login\nint64\n1 if login is to a guest account; 0 otherwise.\n\n\ncount\nint64\nNumber of connections to the same host in the past 2 seconds.\n\n\nsrv_count\nint64\nNumber of connections to the same service in the past 2 seconds.\n\n\nserror_rate\nfloat64\n% of connections with SYN errors.\n\n\nsrv_serror_rate\nfloat64\n% of connections to the same service with SYN errors.\n\n\nrerror_rate\nfloat64\n% of connections with REJ errors.\n\n\nsrv_rerror_rate\nfloat64\n% of connections to the same service with REJ errors.\n\n\nsame_srv_rate\nfloat64\n% of connections to the same service.\n\n\ndiff_srv_rate\nfloat64\n% of connections to different services.\n\n\nsrv_diff_host_rate\nfloat64\n% of connections to different hosts on the same service.\n\n\ndst_host_count\nint64\nNumber of connections to the destination host.\n\n\ndst_host_srv_count\nint64\nNumber of connections to the destination host and service.\n\n\ndst_host_same_srv_rate\nfloat64\n% of connections to the same service on the destination host.\n\n\ndst_host_diff_srv_rate\nfloat64\n% of connections to different services on the destination host.\n\n\ndst_host_same_src_port_rate\nfloat64\n% of connections from the same source port.\n\n\ndst_host_srv_diff_host_rate\nfloat64\n% of connections to the same service from different hosts.\n\n\ndst_host_serror_rate\nfloat64\n% of connections with SYN errors to the destination host.\n\n\ndst_host_srv_serror_rate\nfloat64\n% of connections with SYN errors to the destination service.\n\n\ndst_host_rerror_rate\nfloat64\n% of connections with REJ errors to the destination host.\n\n\ndst_host_srv_rerror_rate\nfloat64\n% of connections with REJ errors to the destination service.\n\n\nattack\nobject\nLabel indicating the type of attack or “normal”.\n\n\nlevel\nint64\nSeverity or confidence score of the attack (if available).\n\n\n\n\n\nExploratory Data Analysis\nWe take a quick look at the training data to see if there are any obvious imbalances.\n\nprint(\"Shape:\", df_train.shape)\nprint(\"Missing values:\", df_train.isna().sum().sum())\nprint(\"Duplicates:\", df_train.duplicated().sum())\nprint(\"Unique attack labels:\", df_train['attack'].nunique())\nprint(\"Attack label distribution:\\n\", df_train['attack'].value_counts().head(5))\n\n# Show types and non-null counts\ndf_train.info(verbose=False)\n\nShape: (125972, 43)\nMissing values: 0\nDuplicates: 0\nUnique attack labels: 23\nAttack label distribution:\n attack\nnormal       67342\nneptune      41214\nsatan         3633\nipsweep       3599\nportsweep     2931\nName: count, dtype: int64\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 125972 entries, 0 to 125971\nColumns: 43 entries, duration to level\ndtypes: float64(15), int64(24), object(4)\nmemory usage: 41.3+ MB\n\n\nThe brief look at the data is positive. There are plenty of data points and features, depending on time speeds for fitting models, we may decrease our sample size because hyper parameter using GridSearchCV training may be time intensive. In the data there are no missing values, and the glimpse of the attack column provides insight into why we want to collapse it into a binary column.\n\n\nNormal vs Anomalous Traffic\nFirst, look at the amount of normal v. anomalous data.\n\n\n\n\n\n\n\n\n\nattack\nnormal             67342\nneptune            41214\nsatan               3633\nipsweep             3599\nportsweep           2931\nsmurf               2646\nnmap                1493\nback                 956\nteardrop             892\nwarezclient          890\npod                  201\nguess_passwd          53\nbuffer_overflow       30\nwarezmaster           20\nland                  18\nimap                  11\nrootkit               10\nloadmodule             9\nftp_write              8\nmultihop               7\nphf                    4\nperl                   3\nspy                    2\nName: count, dtype: int64\n\n\nThe plot provides an idea of the specific attack types expressesd in the data. The plot communicates why it makes sense to group all non-normal traffic together.\nWe feature engineer a new column, is_anomalous, this contains 0 if the connection is normal and 1 if the connection is not normal.\n\n# create binary target column: 1 = attack, 0 = normal\n\ndf_train['is_anomalous'] = df_train['attack'].apply(\n  lambda x: 0 if x == 'normal' else 1)\n\nExamine the new column, is_anaomalous, to get an idea of the target frequency.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCount\nPercentage\n\n\nis_anomalous\n\n\n\n\n\n\nNormal\n67342\n53.46\n\n\nAttack\n58630\n46.54\n\n\n\n\n\n\n\nThe is_anomalous classification target shows a near-even class distribution indicating the the dataset is well balanced. There should be no need for resampling or class weighting to correct the set. It appears this dataset will be a good candidate for learning models."
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "Packet Traffic Learning",
    "section": "Analysis plan",
    "text": "Analysis plan\n\nProblem Introduction\nThe project is to build and evaluate models capable of detecting anomalous network traffic based on connection-level features from the NSL-KDD dataset. The problem is framed as a binary classification task, where each record is labeled as either normal or anomalous. This has real-world applications in intrusion detection systems and network security monitoring.\nThe project will explore both supervised and unsupervised machine learning techniques to assess their effectiveness in identifying attacks from structured network traffic data.\n\n\nFeature Engineering Strategy\nTo ensure a fair and consistent comparison, we will apply the same feature engineering pipeline to both supervised and unsupervised models. All features will be assigned appropriate column names based on the NSL-KDD documentation. Categorical variables such as protocol_type, service, and flag will be one-hot encoded, and low-variance or non-informative columns will be removed. Numeric features will be standardized using a scaler to normalize their ranges.\nFor supervised models, these engineered features will be used alongside the binary target is_anomalous. For unsupervised models, the same processed features will be used without labels, allowing the models to explore underlying structure or detect anomalous patterns. This consistent preprocessing ensures that differences in performance can be attributed to the modeling approaches rather than inconsistencies in data preparation.\n\n\nDimensionality Reduction\nOur dataset currently has over 40 features, we will apply a combination of feature reduction techniques such as Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), or even use the Random Forest Classifier feature importance attribute. We’ll experiment to determine the most optimal feature subset for our classification task.\n\n\nQ1. Supervised Learning\nFor the supervised learning portion of the project, we will train and evaluate models using the labeled NSL-KDD dataset to classify network traffic as normal or anomalous. Specifically, we will implement and compare a Long Short-Term Memory (LSTM) neural network and a Support Vector Machine (SVM). These models will be trained on the same feature-engineered data, using the is_anomalous column as the target. Model performance will be assessed using standard classification metrics, including accuracy, precision, recall, F1-score, and ROC AUC.\n\n\nQ2. Unsupervised Learning\nFor the unsupervised learning portion of the project, we will explore clustering-based approaches to detect anomalies in network traffic without relying on labeled data. We plan to experiment with techniques such as K-Means and DBSCAN to group similar observations and identify outliers that may correspond to attacks. After clustering, we will evaluate how well the resulting groupings align with the true labels using appropriate metrics for unsupervised learning. This will help us assess the potential of unsupervised models to detect anomalous behavior in the absence of supervision.\n\n\nSummary Comparison\nTo compare the supervised and unsupervised approaches, we will evaluate their ability to correctly identify anomalous traffic using relevant metrics for each method. We will also consider practical factors such as interpretability, scalability, and the need for labeled data.\n\n\nProject Timeline\n\n\n\n\n\n\n\n\n\n\nTask Name\nStatus\nDue\nPriority\nSummary\n\n\n\n\nDataset exploration\nIn Progress\nWeek 1\nHigh\nLoad the dataset, inspect features, handle any preprocessing needs.\n\n\nDefine research questions\nComplete\nWeek 1\nHigh\nClarify goals for supervised and unsupervised anomaly detection.\n\n\nSupervised model development\nNot Started\nWeek 2\nHigh\nTrain models like Random Forest, Logistic Regression, and XGBoost.\n\n\nEvaluation of supervised models\nNot Started\nWeek 3\nHigh\nUse accuracy, precision, recall, F₁, and ROC-AUC to assess performance.\n\n\nUnsupervised model development\nNot Started\nWeek 3\nMedium\nExplore methods like Isolation Forest and clustering.\n\n\nEvaluation of unsupervised models\nNot Started\nWeek 4\nMedium\nCompare anomaly scores to labeled data using precision-recall metrics.\n\n\nComparative analysis\nNot Started\nWeek 4\nHigh\nAnalyze strengths and weaknesses of both approaches.\n\n\nFinal report & presentation\nNot Started\nWeek 5\nHigh\nCompile results, figures, and discussion into final deliverables."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Title",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Project Title",
    "section": "",
    "text": "Add project abstract here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by The Anomalists For INFO 523 - Data Mining and Discovery at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nJoey Garcia. First-year Master of Science in Data Science student with a keen interest in Artifical Intelligence architecture.\nS. David Kyle. First-year Master of Science in Data Science student with a professional background in software engineering."
  },
  {
    "objectID": "presentation.html#quarto",
    "href": "presentation.html#quarto",
    "title": "Project title",
    "section": "Quarto",
    "text": "Quarto\n\nThe presentation is created using the Quarto CLI\n## sets the start of a new slide"
  },
  {
    "objectID": "presentation.html#layouts",
    "href": "presentation.html#layouts",
    "title": "Project title",
    "section": "Layouts",
    "text": "Layouts\nYou can use plain text\n\n\n\nor bullet points1\n\n\nor in two columns\n\n\nlike\nthis\n\nAnd add footnotes"
  },
  {
    "objectID": "presentation.html#code",
    "href": "presentation.html#code",
    "title": "Project title",
    "section": "Code",
    "text": "Code\n\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    mpg   R-squared:                       0.073\nModel:                            OLS   Adj. R-squared:                  0.070\nMethod:                 Least Squares   F-statistic:                     30.59\nDate:                Fri, 01 Aug 2025   Prob (F-statistic):           5.84e-08\nTime:                        22:35:55   Log-Likelihood:                -1346.4\nNo. Observations:                 392   AIC:                             2697.\nDf Residuals:                     390   BIC:                             2705.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         35.8015      2.266     15.800      0.000      31.347      40.257\nspeed       -354.7055     64.129     -5.531      0.000    -480.788    -228.623\n==============================================================================\nOmnibus:                       27.687   Durbin-Watson:                   0.589\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               18.976\nSkew:                           0.420   Prob(JB):                     7.57e-05\nKurtosis:                       2.323   Cond. No.                         169.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "presentation.html#plots",
    "href": "presentation.html#plots",
    "title": "Project title",
    "section": "Plots",
    "text": "Plots"
  },
  {
    "objectID": "presentation.html#plot-and-text",
    "href": "presentation.html#plot-and-text",
    "title": "Project title",
    "section": "Plot and text",
    "text": "Plot and text\n\n\n\nSome text\ngoes here"
  },
  {
    "objectID": "presentation.html#tables",
    "href": "presentation.html#tables",
    "title": "Project title",
    "section": "Tables",
    "text": "Tables\nIf you want to generate a table, make sure it is in the HTML format (instead of Markdown or other formats), e.g.,\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\n\n\n\nisland\n\n\n\nbill_length_mm\n\n\n\nbill_depth_mm\n\n\n\nflipper_length_mm\n\n\n\nbody_mass_g\n\n\n\nsex\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.1\n\n\n\n18.7\n\n\n\n181.0\n\n\n\n3750.0\n\n\n\nMale\n\n\n\n\n\n\n\n1\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.5\n\n\n\n17.4\n\n\n\n186.0\n\n\n\n3800.0\n\n\n\nFemale\n\n\n\n\n\n\n\n2\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n40.3\n\n\n\n18.0\n\n\n\n195.0\n\n\n\n3250.0\n\n\n\nFemale\n\n\n\n\n\n\n\n4\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n36.7\n\n\n\n19.3\n\n\n\n193.0\n\n\n\n3450.0\n\n\n\nFemale\n\n\n\n\n\n\n\n5\n\n\n\nAdelie\n\n\n\nTorgersen\n\n\n\n39.3\n\n\n\n20.6\n\n\n\n190.0\n\n\n\n3650.0\n\n\n\nMale"
  },
  {
    "objectID": "presentation.html#images",
    "href": "presentation.html#images",
    "title": "Project title",
    "section": "Images",
    "text": "Images\n\nImage credit: Danielle Navarro, Percolate."
  },
  {
    "objectID": "presentation.html#math-expressions",
    "href": "presentation.html#math-expressions",
    "title": "Project title",
    "section": "Math Expressions",
    "text": "Math Expressions\nYou can write LaTeX math expressions inside a pair of dollar signs, e.g. $\\alpha+\\beta$ renders \\(\\alpha + \\beta\\). You can use the display style with double dollar signs:\n$$\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i$$\n\\[\n\\bar{X}=\\frac{1}{n}\\sum_{i=1}^nX_i\n\\]\nLimitations:\n\nThe source code of a LaTeX math expression must be in one line, unless it is inside a pair of double dollar signs, in which case the starting $$ must appear in the very beginning of a line, followed immediately by a non-space character, and the ending $$ must be at the end of a line, led by a non-space character;\nThere should not be spaces after the opening $ or before the closing $."
  },
  {
    "objectID": "presentation.html#feeling-adventurous",
    "href": "presentation.html#feeling-adventurous",
    "title": "Project title",
    "section": "Feeling adventurous?",
    "text": "Feeling adventurous?\n\nYou are welcomed to use the default styling of the slides. In fact, that’s what I expect majority of you will do. You will differentiate yourself with the content of your presentation.\nBut some of you might want to play around with slide styling. Some solutions for this can be found at https://quarto.org/docs/presentations/revealjs."
  }
]
---
title: "Packet Traffic Learning"
subtitle: "Proposal"
author: 
  - name: "The Anomalists - Joey Garcia, David Kyle"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "Project description: Our project aims to develop a predictive model to detect anomalous network behavior using packet-level and statistical features derived from network traffic. With machine learning models, we aim to accurately classify and predict network anomalies, which is essential for intrusion detection, network security monitoring, and incident response automation."
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
execute:
  warning: false
jupyter: python3
---

```{python}
#| label: load-pkgs
#| message: false
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats # for analysis plan
```

## Dataset

```{python}
#| label: load-dataset
#| message: false

network_traffic_test = pd.read_csv('data/KDDTest+.txt')
network_traffic_train = pd.read_csv('data/KDDTrain+.txt')

df_train = network_traffic_test.copy()
df_test = network_traffic_train.copy()

'''
Columns recieved from kaggle project 
https://www.kaggle.com/code/faizankhandeshmukh/intrusion-detection-system

'''

# Define the list of column names based on the NSL-KDD dataset description
columns = [
    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',
    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',
    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',
    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',
    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',
    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',
    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',
    'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',
    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',
    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
    'dst_host_srv_rerror_rate', 'attack', 'level'
]

# Assign the column names to the dataframe
df_test.columns = columns
df_train.columns = columns

print('Shapes (test, train):', df_test.shape, df_train.shape)
```

We are using testing and training network intrusion detection datasets from [NSL-KDD from Kaggle](https://www.kaggle.com/datasets/hassan06/nslkdd/data?select=KDDTrain1.jpg), which contains **12,5972 rows** and **43 columns** of labeled intrusion detection network traffic in the test dataset. The `attack` field indicates normal or anomalous (multi-class) observations which allows us to use supervised learning approaches for classifying anomalous network activity.

We chose this dataset because it provides a rich and realistic representation of network traffic data. The presence of labeled data allows us to train and evaluate supervised models; the diversity and volume of traffic patterns make it well-suited for exploring unsupervised anomaly detection techniques as well. This balance between complexity and feature richness aligns well with our research questions and modeling goals.

```{python}
#| label: preview-data-columns
cols_test = df_test.columns

for col in cols_test:
  print(col)
```

## Questions

Q1. Using supervised machine learning models such as Long Short-Term Memory (LSTM) and Support Vector Machines (SVMs), can we accurately calssify network traffic as normal and anomalous based on labeled data? How do their performances compare in terms of accuracy, precision, recall, and F1-score?

Q2. Can unsupervised learning methods such as K-Means Clustering and Density-Based Clustering (DBSCAN) detect anomalous patterns in network traffic without using labeled data?

Summary. How do the supervised and unsupervised approaches compare?

## Analysis plan

### Variables

| Column Name                  | Data Type | Description                                                                 |
|-----------------------------|-----------|-----------------------------------------------------------------------------|
| `duration`                  | int64     | Length (in seconds) of the connection.                                      |
| `protocol_type`             | object    | Protocol used (e.g., tcp, udp, icmp).                                       |
| `service`                   | object    | Network service on the destination (e.g., http, telnet).                    |
| `flag`                      | object    | Status flag of the connection.                                              |
| `src_bytes`                 | int64     | Number of data bytes sent from source to destination.                       |
| `dst_bytes`                 | int64     | Number of data bytes sent from destination to source.                       |
| `land`                      | int64     | 1 if connection is from/to the same host/port; 0 otherwise.                 |
| `wrong_fragment`            | int64     | Number of wrong fragments.                                                  |
| `urgent`                    | int64     | Number of urgent packets.                                                   |
| `hot`                       | int64     | Number of "hot" indicators.                                                 |
| `num_failed_logins`         | int64     | Number of failed login attempts.                                            |
| `logged_in`                 | int64     | 1 if successfully logged in; 0 otherwise.                                   |
| `num_compromised`           | int64     | Number of compromised conditions.                                           |
| `root_shell`                | int64     | 1 if root shell is obtained; 0 otherwise.                                   |
| `su_attempted`              | int64     | 1 if "su root" command attempted; 0 otherwise.                              |
| `num_root`                  | int64     | Number of "root" accesses.                                                  |
| `num_file_creations`        | int64     | Number of file creation operations.                                         |
| `num_shells`                | int64     | Number of shell prompts invoked.                                            |
| `num_access_files`          | int64     | Number of accesses to control files.                                        |
| `num_outbound_cmds`         | int64     | Number of outbound commands (always 0 in KDD99).                            |
| `is_host_login`             | int64     | 1 if login is to a host account; 0 otherwise.                               |
| `is_guest_login`            | int64     | 1 if login is to a guest account; 0 otherwise.                              |
| `count`                     | int64     | Number of connections to the same host in the past 2 seconds.              |
| `srv_count`                 | int64     | Number of connections to the same service in the past 2 seconds.           |
| `serror_rate`               | float64   | % of connections with SYN errors.                                           |
| `srv_serror_rate`           | float64   | % of connections to the same service with SYN errors.                       |
| `rerror_rate`               | float64   | % of connections with REJ errors.                                           |
| `srv_rerror_rate`           | float64   | % of connections to the same service with REJ errors.                       |
| `same_srv_rate`             | float64   | % of connections to the same service.                                       |
| `diff_srv_rate`             | float64   | % of connections to different services.                                     |
| `srv_diff_host_rate`        | float64   | % of connections to different hosts on the same service.                    |
| `dst_host_count`            | int64     | Number of connections to the destination host.                              |
| `dst_host_srv_count`        | int64     | Number of connections to the destination host and service.                 |
| `dst_host_same_srv_rate`    | float64   | % of connections to the same service on the destination host.               |
| `dst_host_diff_srv_rate`    | float64   | % of connections to different services on the destination host.             |
| `dst_host_same_src_port_rate` | float64 | % of connections from the same source port.                                 |
| `dst_host_srv_diff_host_rate` | float64 | % of connections to the same service from different hosts.                  |
| `dst_host_serror_rate`      | float64   | % of connections with SYN errors to the destination host.                   |
| `dst_host_srv_serror_rate`  | float64   | % of connections with SYN errors to the destination service.                |
| `dst_host_rerror_rate`      | float64   | % of connections with REJ errors to the destination host.                   |
| `dst_host_srv_rerror_rate`  | float64   | % of connections with REJ errors to the destination service.                |
| `attack`                    | object    | Label indicating the type of attack or "normal".                            |
| `level`                     | int64     | Severity or confidence score of the attack (if available).                  |


### Exploratory Data Analysis

We take a quick look at the data to see if the data is telling anything right away.

```{python}
#| label: Exploratory Data Analysis
print("Info:\n", df_train.info())
print("\nDescribe the numerics:\n",df_train.describe())
print("\nDuplicates:",df_train.duplicated().sum())
```


## Normal vs Anomalous Traffic

First, look at the amount of normal v. anomalous data.

```{python}
#| label: class-distribution
#| echo: false
#| message: false
#| warning: false

# plot style
sns.set(style="whitegrid")

# plot
plt.figure(figsize=(10, 4))
sns.countplot(
  data=df_test, 
  x="attack",
  hue="attack", 
  palette="Set2",
  order=df_test['attack'].value_counts().index
  )

plt.title("Distribution of Normal vs Anomalous Traffic")
plt.xlabel("Attack Type")
plt.ylabel("Count")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

print(df_test['attack'].value_counts())

```

The plot suggests 

## Timeline

### Project Timeline

| Task Name | Status | Due | Priority | Summary |
|-----------|-----------|-----------|-----------|------------------------------|
| Dataset exploration | In Progress | Week 1 | High | Load the dataset, inspect features, handle any preprocessing needs. |
| Define research questions | Complete | Week 1 | High | Clarify goals for supervised and unsupervised anomaly detection. |
| Supervised model development | Not Started | Week 2 | High | Train models like Random Forest, Logistic Regression, and XGBoost. |
| Evaluation of supervised models | Not Started | Week 3 | High | Use accuracy, precision, recall, F‚ÇÅ, and ROC-AUC to assess performance. |
| Unsupervised model development | Not Started | Week 3 | Medium | Explore methods like Isolation Forest and clustering. |
| Evaluation of unsupervised models | Not Started | Week 4 | Medium | Compare anomaly scores to labeled data using precision-recall metrics. |
| Comparative analysis | Not Started | Week 4 | High | Analyze strengths and weaknesses of both approaches. |
| Final report & presentation | Not Started | Week 5 | High | Compile results, figures, and discussion into final deliverables. |